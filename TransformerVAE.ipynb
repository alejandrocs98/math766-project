{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer VAE + Regressor for Species Abundance\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Feature Embedding ---\n",
    "class FeatureEmbedding(nn.Module):\n",
    "    def __init__(self, num_features, d_model):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_features, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_features = x.shape\n",
    "        indices = torch.arange(num_features).unsqueeze(0).repeat(batch_size, 1).to(x.device)\n",
    "        return self.embedding(indices)\n",
    "\n",
    "# --- Transformer Encoder ---\n",
    "class TransformerEncoderVAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, d_model=128, n_heads=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(1, d_model)\n",
    "        self.feature_embed = FeatureEmbedding(input_dim, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_mu = nn.Linear(input_dim * d_model, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(input_dim * d_model, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(-1)  # (B, F) -> (B, F, 1)\n",
    "        x = self.input_proj(x) + self.feature_embed(x.squeeze(-1))\n",
    "        h = self.transformer_encoder(x)\n",
    "        h_flat = self.flatten(h)\n",
    "        mu = self.fc_mu(h_flat)\n",
    "        logvar = self.fc_logvar(h_flat)\n",
    "        return mu, logvar\n",
    "\n",
    "# --- Decoder ---\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "# --- Full VAE ---\n",
    "class TransformerVAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoderVAE(input_dim, latent_dim)\n",
    "        self.decoder = TransformerDecoder(latent_dim, input_dim)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decoder(z)\n",
    "        return recon_x, mu, logvar, z\n",
    "\n",
    "# --- MLP Regressor ---\n",
    "class LatentToSpeciesRegressor(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "# --- Loss Function ---\n",
    "def vae_loss_function(recon_x, x, mu, logvar):\n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction='mean')\n",
    "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)\n",
    "    return recon_loss + kld, recon_loss, kld\n",
    "\n",
    "# --- Example Training Loop Placeholder ---\n",
    "# To use: Load your data into `X`, create dataloader, and loop over epochs.\n",
    "\n",
    "# Example usage:\n",
    "# vae = TransformerVAE(input_dim=X.shape[1], latent_dim=32)\n",
    "# regressor = LatentToSpeciesRegressor(latent_dim=32, output_dim=X.shape[1])\n",
    "# optimizer = optim.Adam(list(vae.parameters()) + list(regressor.parameters()), lr=1e-3)\n",
    "# for epoch in range(epochs):\n",
    "#     for batch in dataloader:\n",
    "#         x = batch[0]\n",
    "#         recon_x, mu, logvar, z = vae(x)\n",
    "#         y_pred = regressor(z)\n",
    "#         loss_vae, recon_loss, kld = vae_loss_function(recon_x, x, mu, logvar)\n",
    "#         loss_pred = F.mse_loss(y_pred, x)\n",
    "#         loss = loss_vae + loss_pred\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     print(f\"Epoch {epoch}: VAE Loss={loss_vae.item():.4f}, Pred Loss={loss_pred.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
